{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport subprocess\nimport time\nimport getpass\nfrom pyngrok import ngrok","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Change directory to the working directory\nos.chdir('/kaggle/working/')\nprint(f\"Current working directory: {os.getcwd()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set environment variables for Ollama\nos.environ['OLLAMA_HOST'] = \"0.0.0.0\"\nos.environ['OLLAMA_ORIGINS'] = \"*\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to run commands and check for errors\ndef run(commands):\n    for command in commands:\n        with subprocess.Popen(\n            command,\n            shell=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,  # Use text mode to avoid binary mode issues\n            bufsize=1,  # Line buffering is supported in text mode\n            universal_newlines=True  # Ensure compatibility with text mode\n        ) as sp:\n            for line in sp.stdout:\n                if \"undefined reference\" in line:\n                    raise RuntimeError(\"Failed Processing.\")\n                print(line, flush=True, end=\"\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start the Ollama server in the background and add a short delay\nprint(\"Starting Ollama server...\")\nos.system(\"/usr/local/bin/ollama serve &\")\ntime.sleep(5)  # Give the server some time to start","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run the echo command\nos.system(\"echo 'ollama test'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install Ollama\nprint(\"Installing Ollama...\")\ncommands = [\n    \"curl -fsSL https://ollama.com/install.sh | sh\",\n]\nrun(commands)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a custom Ollama model file\nprint(\"Creating custom Ollama model file...\")\nwith open('/kaggle/working/ModelFilesabs', 'w') as f:\n    f.write(\"FROM llama3\\nPARAMETER num_ctx=32768\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pull the Deepseek model\nprint(\"Pulling Deepseek model...\")\ncommands = [\n    \"ollama pull deepseek-r1:14b\"\n]\nrun(commands)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install Nginx\nprint(\"Installing Nginx...\")\ncommands = [\n    \"apt install nginx -y\"\n]\nrun(commands)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configure Nginx for Ollama\nprint(\"Configuring Nginx for Ollama...\")\nnginx_config = \"\"\"\nserver {\n    listen 80;\n    server_name *.ngrok-free.app;\n\n    location / {\n        proxy_pass http://localhost:11434;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n\"\"\"\nwith open('/etc/nginx/conf.d/ollamasvc.conf', 'w') as f:\n    f.write(nginx_config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install pyngrok and ngrok\nprint(\"Installing pyngrok and ngrok...\")\nos.system(\"!pip install pyngrok ngrok --force\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prompt for the Ngrok token\nngrok_token = getpass.getpass('Enter your Ngrok access token and press enter: ')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the Ngrok authtoken\nprint(\"Setting Ngrok authtoken...\")\ncommands = [\n    f\"ngrok authtoken {ngrok_token}\"\n]\nrun(commands)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Connect Ngrok to expose the Ollama server\nprint(\"Starting Ngrok tunnel...\")\nlistener = ngrok.connect(addr=\"localhost:80\", metadata=\"Ollama server\")\nprint(f\"Please click on the text below to access the Ollama server: {listener}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Restart Nginx to apply the configuration\nprint(\"Restarting Nginx...\")\nos.system(\"sudo /etc/init.d/nginx stop\")\nos.system(\"sudo /etc/init.d/nginx start\")\n\nprint(\"Setup complete! Ollama server is running and accessible via Ngrok.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}